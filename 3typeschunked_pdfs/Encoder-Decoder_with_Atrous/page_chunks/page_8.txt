8 L.-C Chen, Y. Zhu, G. Papandreou, F. Schroﬀ, and H. Adam
4.1 Decoder Design Choices
We deﬁne “DeepLabv3 feature map” as the last feature map computed by
DeepLabv3 ( i.e., the features containing ASPP features and image-level fea-
tures), and [ k×k,f] as a convolution operation with kernel k×kandfﬁlters.
When employing output stride = 16, ResNet-101 based DeepLabv3 [ 23] bi-
linearly upsamples the logits by 16 during both training and evaluation. This
simplebilinearupsamplingcouldbeconsideredasanaivedecoderd esign,attain-
ing the performance of 77 .21% [23] on PASCAL VOC 2012 valset and is 1 .2%
better than not using this naive decoder during training ( i.e., downsampling
groundtruth during training). To improve over this naive baseline , our proposed
model “DeepLabv3+” adds the decoder module on top of the encoder output , as
shown in Fig. 2. In the decoder module, we consider three places for diﬀerent de -
sign choices, namely (1) the 1 ×1 convolution used to reduce the channels of the
low-level feature map from the encoder module, (2) the 3 ×3 convolution used
to obtain sharper segmentation results, and (3) what encoder low-leve l features
should be used.
To evaluate the eﬀect of the 1 ×1 convolution in the decoder module, we
employ [3 ×3,256] and the Conv2 features from ResNet-101 network backbone,
i.e., the last feature map in res2x residual block (to be concrete, we us e the
feature map before striding). As shown in Tab. 1, reducing the channels of the
low-level feature map from the encoder module to either 48 or 32 leads to better
performance. We thus adopt [1 ×1,48] for channel reduction.
We then design the 3 ×3 convolution structure for the decoder module and
report the ﬁndings in Tab. 2. We ﬁnd that after concatenating the Conv2 feature
map(beforestriding)withDeepLabv3featuremap,itismoreeﬀective toemploy
two3×3convolutionwith256ﬁltersthanusingsimplyoneorthreeconvolutions .
Changing the number of ﬁlters from 256 to 128 or the kernel size from 3 ×3 to
1×1 degrades performance. We also experiment with the case where both C onv2
and Conv3 feature maps are exploited in the decoder module. In this c ase, the
decoder feature map are gradually upsampled by 2, concatenated with Conv3
ﬁrst and then Conv2, and each will be reﬁned by the [3 ×3,256] operation. The
whole decoding procedure is then similar to the U-Net/SegNet design [ 21,22].
However, we have not observed signiﬁcant improvement. Thus, in th e end, we
adopt the very simple yet eﬀective decoder module: the concatenat ion of the
DeepLabv3 feature map and the channel-reduced Conv2 feature map are reﬁ ned
by two [3 ×3,256] operations. Note that our proposed DeepLabv3+ model has
output stride = 4. We do not pursue further denser output feature map ( i.e.,
output stride <4) given the limited GPU resources.
4.2 ResNet-101 as Network Backbone
To compare the model variants in terms of both accuracy and speed, we rep ort
mIOU and Multiply-Adds in Tab. 3when using ResNet-101 [ 25] as network
backbone in the proposed DeepLabv3+ model. Thanks to atrous convolution, w e