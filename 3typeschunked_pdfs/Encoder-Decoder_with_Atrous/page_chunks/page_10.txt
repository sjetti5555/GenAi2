10 L.-C Chen, Y. Zhu, G. Papandreou, F. Schroﬀ, and H. Adam
Model Top-1 Error Top-5 Error
Reproduced ResNet-101 22.40% 6.02%
Modiﬁed Xception 20.19% 5.17%
Table 4. Single-model error rates on ImageNet-1K validation set.
Baseline: TheﬁrstrowblockinTab. 3containstheresultsfrom[ 23]showing
that extracting denser feature maps during evaluation ( i.e.,eval output stride =
8) and adopting multi-scale inputs increases performance. Besides, adding left-
right ﬂipped inputs doubles the computation complexity with only mar ginal
performance improvement.
Adding decoder: The second row block in Tab. 3contains the results when
adopting the proposed decoder structure. The performance is impro ved from
77.21% to 78 .85% or 78 .51% to 79 .35% when using eval output stride = 16 or 8,
respectively, at the cost of about 20B extra computation overhead. The pe rfor-
mance is further improved when using multi-scale and left-right ﬂipped inputs.
Coarser feature maps: We also experiment with the case when using
train output stride = 32 (i.e., no atrous convolution at all during training) for
fast computation. As shown in the third row block in Tab. 3, adding the decoder
brings about 2% improvement while only 74.20B Multiply-Adds are require d.
However, the performance is always about 1% to 1.5% below the case in whic h
we employ train output stride = 16 and diﬀerent eval output stride values. We
thus prefer using output stride = 16 or 8 during training or evaluation depending
on the complexity budget.
4.3 Xception as Network Backbone
We further employ the more powerful Xception [ 26] as network backbone. Fol-
lowing [31], we make a few more changes, as described in Sec. 3.2.
ImageNet pretraining: The proposed Xception network is pretrained on
ImageNet-1k dataset [ 74] with similar training protocol in [ 26]. Speciﬁcally, we
adopt Nesterov momentum optimizer with momentum = 0.9, initial learnin g
rate = 0.05, rate decay = 0.94 every 2 epochs, and weight decay 4 e−5. We
use asynchronous training with 50 GPUs and each GPU has batch size 32 with
image size 299 ×299. We did not tune the hyper-parameters very hard as the goal
is to pretrain the model on ImageNet for semantic segmentation. We report the
single-model error rates on the validation set in Tab. 4along with the baseline
reproduced ResNet-101 [ 25] under the same training protocol. We have observed
0.75% and 0.29% performance degradation for Top1 and Top5 accuracy when
not adding the extra batch normalization and ReLU after each 3 ×3 depthwise
convolution in the modiﬁed Xception.
The results of using the proposed Xception as network backbone for semant ic
segmentation are reported in Tab. 5.
Baseline: We ﬁrst report the results without using the proposed decoder in
the ﬁrst row block in Tab. 5, which shows that employing Xception as network