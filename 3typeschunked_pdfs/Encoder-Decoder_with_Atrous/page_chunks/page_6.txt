6 L.-C Chen, Y. Zhu, G. Papandreou, F. Schroﬀ, and H. Adam
tures [52]. We use the last feature map before logits in the original DeepLabv3
as the encoder output in our proposed encoder-decoder structure. Note the en-
coder output feature map contains 256 channels and rich semantic informat ion.
Besides, one could extract features at an arbitrary resolution by applyi ng the
atrous convolution, depending on the computation budget.
Proposed decoder: The encoder features from DeepLabv3 are usually com-
puted with output stride = 16. In the work of [ 23], the features are bilinearly
upsampled by a factor of 16, which could be considered a naive decoder mo dule.
However, this naive decoder module may not successfully recove r object seg-
mentation details. We thus propose a simple yet eﬀective decoder m odule, as
illustrated in Fig. 2. The encoder features are ﬁrst bilinearly upsampled by a
factor of 4 and then concatenated with the corresponding low-level feat ures [73]
from the network backbone that have the same spatial resolution ( e.g., Conv2
before striding in ResNet-101 [ 25]). We apply another 1 ×1 convolution on the
low-level features to reduce the number of channels, since the c orresponding low-
level features usually contain a large number of channels ( e.g., 256 or 512) which
may outweigh the importance of the rich encoder features (only 256 chann els in
our model) and make the training harder. After the concatenation, we appl y a
few 3×3 convolutions to reﬁne the features followed by another simple bili near
upsampling by a factor of 4. We show in Sec. 4that using output stride = 16
for the encoder module strikes the best trade-oﬀ between speed an d accuracy.
The performance is marginally improved when using output stride = 8 for the
encoder module at the cost of extra computation complexity.
3.2 Modiﬁed Aligned Xception
The Xception model [ 26] has shown promising image classiﬁcation results on Im-
ageNet [74] with fast computation. More recently, the MSRA team [ 31] modiﬁes
the Xception model (called Aligned Xception) and further pushes the p erfor-
mance in the task of object detection. Motivated by these ﬁndings, we w ork in
the same direction to adapt the Xception model for the task of semantic im age
segmentation. In particular, we make a few more changes on top of MSRA’s
modiﬁcations, namely (1) deeper Xception same as in [ 31] except that we do
not modify the entry ﬂow network structure for fast computation and me mory
eﬃciency, (2) all max pooling operations are replaced by depthwise sep arable
convolution with striding, which enables us to apply atrous separable convolu-
tionto extract feature maps at an arbitrary resolution (another option is to
extend the atrous algorithm to max pooling operations), and (3) extra batch
normalization [ 75] and ReLU activation are added after each 3 ×3 depthwise
convolution, similar to MobileNet design [ 29]. See Fig. 4for details.
4 Experimental Evaluation
We employ ImageNet-1k [ 74] pretrained ResNet-101 [ 25] or modiﬁed aligned
Xception [ 26,31] to extract dense feature maps by atrous convolution. Our im-
plementation is built on TensorFlow [ 72] and is made publicly available.