12 L.-C Chen, Y. Zhu, G. Papandreou, F. Schroﬀ, and H. Adam
EncoderDecoder MS Flip SC COCO JFT mIOU Multiply-Addstrain OS eval OS
16 16 79.17% 68.00B
16 16 /check 80.57% 601.74B
16 16 /check /check 80.79% 1203.34B
16 8 79.64% 240.85B
16 8 /check 81.15% 2149.91B
16 8 /check /check 81.34% 4299.68B
16 16 /check 79.93% 89.76B
16 16 /check /check 81.38% 790.12B
16 16 /check /check /check 81.44% 1580.10B
16 8 /check 80.22% 262.59B
16 8 /check /check 81.60% 2338.15B
16 8 /check /check /check 81.63% 4676.16B
16 16 /check /check 79.79% 54.17B
16 16 /check /check /check /check 81.21% 928.81B
16 8 /check /check 80.02% 177.10B
16 8 /check /check /check /check 81.39% 3055.35B
16 16 /check /check /check 82.20% 54.17B
16 16 /check /check /check /check /check 83.34% 928.81B
16 8 /check /check /check 82.45% 177.10B
16 8 /check /check /check /check /check 83.58% 3055.35B
16 16 /check /check /check /check 83.03% 54.17B
16 16 /check /check /check /check /check /check 84.22% 928.81B
16 8 /check /check /check /check 83.39% 177.10B
16 8 /check /check /check /check /check /check 84.56% 3055.35B
Table 5. Inference strategy on the PASCAL VOC 2012 valset when using mod-
iﬁedXception .train OS : Theoutput stride used during training. eval OS : The
output stride usedduringevaluation. Decoder :Employingtheproposeddecoderstruc-
ture.MS: Multi-scale inputs during evaluation. Flip: Adding left-right ﬂipped inputs.
SC: Adopting depthwise separable convolution for both ASPP and d ecoder modules.
COCO: Models pretrained on MS-COCO. JFT: Models pretrained on JFT.
smallest trimap width as shown in the ﬁgure. We also visualize the eﬀ ect of
employing the proposed decoder in Fig. 5(b).
4.5 Experimental Results on Cityscapes
In this section, we experiment DeepLabv3+ on the Cityscapes dataset [ 3], a
large-scale dataset containing high quality pixel-level annotations of 5000 i mages
(2975, 500, and 1525 for the training, validation, and test sets respectively) and
about 20000 coarsely annotated images.
As shown in Tab. 7(a), employing the proposed Xception model as network
backbone (denoted as X-65) on top of DeepLabv3 [ 23], which includes the ASPP