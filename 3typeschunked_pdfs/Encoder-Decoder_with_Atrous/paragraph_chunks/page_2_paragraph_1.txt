2 L.-C Chen, Y. Zhu, G. Papandreou, F. Schroﬀ, and H. Adam
ImageSpatial Pyramid Pooling
0.5x0.5x0.5x
Prediction8x
Image2x
0.5x0.5x0.5x0.5x0.5x 2x
2x
2x
2x
Prediction
ImageSpatial Pyramid Pooling
0.5x0.5x0.5x0.5x4x
Prediction4x
(a) Spatial Pyramid Pooling (b) Encoder-Decoder (c) Encoder-Decoder with Atrous Conv
Fig.1.WeimproveDeepLabv3,whichemploysthespatialpyramidpoolin gmodule(a),
with the encoder-decoder structure (b). The proposed model, Deep Labv3+, contains
rich semantic information from the encoder module, while the deta iled object bound-
aries are recovered by the simple yet eﬀective decoder module. Th e encoder module
allows us to extract features at an arbitrary resolution by applying atrous convolution.
Spatial Pyramid Pooling, or ASPP), while PSPNet [ 24] performs pooling opera-
tionsatdiﬀerentgridscales.Eventhoughrichsemanticinformationis encodedin
the last feature map, detailed information related to object boundaries is missing
due to the pooling or convolutions with striding operations within th e network
backbone. This could be alleviated by applying the atrous convolution to extract
denser feature maps. However, given the design of state-of-art neural n etworks
[7,9,10,25,26] and limited GPU memory, it is computationally prohibitive to ex-
tract output feature maps that are 8, or even 4 times smaller than the inpu t
resolution. Taking ResNet-101 [ 25] for example, when applying atrous convolu-
tion to extract output features that are 16 times smaller than input res olution,
features within the last 3 residual blocks (9 layers) have to be d ilated. Even
worse,26residual blocks ( 78layers!) will be aﬀected if output features that are
8 times smaller than input are desired. Thus, it is computationally i ntensive if
denser output features are extracted for this type of models. On the other hand,
encoder-decoder models [ 21,22] lend themselves to faster computation (since no
features are dilated) in the encoder path and gradually recover sharp ob ject
boundaries in the decoder path. Attempting to combine the advantages from
both methods, we propose to enrich the encoder module in the enco der-decoder
networks by incorporating the multi-scale contextual information.
In particular, our proposed model, called DeepLabv3+, extends DeepLabv 3
[23] by adding a simple yet eﬀective decoder module to recover the object bound-
aries, as illustrated in Fig. 1. The rich semantic information is encoded in the
output of DeepLabv3, with atrous convolution allowing one to control the den -
sity of the encoder features, depending on the budget of computation r esources.
Furthermore, the decoder module allows detailed object boundary r ecovery.
Motivatedbytherecentsuccessofdepthwiseseparableconvolution[ 27,28,26,29,30],
we also explore this operation and show improvement in terms of both sp eed and
accuracy by adapting the Xception model [ 26], similar to [ 31], for the task of